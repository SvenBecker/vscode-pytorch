{   
    "PyTorch Imports": {
        "prefix": "pytorch:imports",
        "description": "Common pytorch imports",
        "body":[
            "import torch",
            "import torch.nn as nn",
            "import torch.nn.functional as F",
            "import torch.optim as optim"
        ]
    },
    "Check Device": {
        "prefix": "pytorch:device",
        "description": "Check the available device",
        "body":[
            "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')"
        ]
    },
    "Optimizer": {
        "prefix": "pytorch:optimizer",
        "description": "Select an optimizer",
        "body":[
            "optimizer = torch.optim.${1|Adadelta,Adagrad,Adam,SparseAdam,Adamax,ASGD,LBFGS,RMSprop,Rprop,SGD|}(${2:net}.parameters(), lr=${3:1e-2})"
        ]
    },
    "Scheduler": {
        "prefix": "pytorch:scheduler",
        "description": "Select a scheduler method to adjust the learning rate",
        "body":[
            "scheduler = torch.optim.lr_scheduler.${1|LambdaLR,StepLR,MultiStepLR,ExponentialLR,CosineAnnealingLR,ReduceLROnPlateau,CyclicLR|}(${2:optimizer})"
        ]
    },
    "Dataset": {
        "prefix": "pytorch:dataset",
        "description": "Template for a custom dataset",
        "body": [
            "class ${1:MyDataset}(torch.utils.data.Dataset):",
            "\t\"\"\"Some Information about ${1:MyDataset}\"\"\"",
            "\tdef __init__(self):",
            "\t\tsuper(${1:MyDataset}, self).__init__()",
            "",
            "\tdef __getitem__(self, index):",
            "\t\treturn $2",
            "",
            "\tdef __len__(self):",
            "\t\treturn $3"
        ]
    },
    "Dataloader": {
        "prefix": "pytorch:dataloader",
        "description": "Template for a dataloader",
        "body": [
            "dataloader = torch.utils.data.DataLoader(${1:dataset}, batch_size=${2:1}, shuffle=${3|False,True|})"
        ]
    },
    "Classification Loss": {
        "prefix": "pytorch:loss_class",
        "description": "Select a loss function for classification provided by pytorch",
        "body":[
            "criterion = nn.${1|CrossEntropyLoss,NLLLoss,PoissonNLLLoss,BCELoss,BCEWithLogitsLoss,MarginRankingLoss,HingeEmbeddingLoss,MultiLabelMarginLoss,SoftMarginLoss,MultiLabelSoftMarginLoss,CosineEmbeddingLoss,MultiMarginLoss,TripletMarginLoss,CTCLoss|}()"
        ]
    },
    "Regression Loss": {
        "prefix": "pytorch:loss_reg",
        "description": "Select a loss function for regression provided by pytorch",
        "body":[
            "criterion = nn.${1|L1Loss,MSELoss,KLDivLoss,SmoothL1Loss|}()"
        ]
    },
    "PyTorch Module": {
        "prefix": "pytorch:module",
        "description": "Creates a custom class template which inherits from torch.nn.Module",
        "body": [
            "class ${1:MyModule}(nn.Module):",            
            "\t\"\"\"Some Information about ${1:MyModule}\"\"\"",
            "\tdef __init__(self):",
            "\t\tsuper(${1:MyModule}, self).__init__()",
            "",
            "\tdef forward(self, x):",
            "",
            "\t\treturn x"
        ]
    },
    "Container": {
        "prefix": "pytorch:container",
        "description": "Stores modules or parameters in some kind of container",
        "body": [
            "layers = nn.${1|Sequential,ModuleList,ModuleDict,ParameterList,ParameterDict|}($2)"
        ]
    },
    "PyTorch Autograd Function": {
        "prefix": "pytorch:function",
        "description": "Creates a custom autograd function template which inherits from torch.autograd.Function",
        "body": [
            "class ${1:MyFunction}(torch.autograd.Function):",            
            "\t\"\"\"Some Information about ${1:MyFunction}\"\"\"",
            "",
            "\t@staticmethod",
            "\tdef forward(ctx, input):",
            "",
            "\t\treturn",
            "",
            "\t@staticmethod",
            "\tdef backward(ctx, grad_output)",
            "",
            "\t\treturn"
        ]
    },
    "Initialize": {
        "prefix": "pytorch:init",
        "description": "Creates an initializer function and applies it to the given neural network",
        "body": [
            "def init_weights(m):",
            "\tclassname = m.__class__.__name__",
            "\tif classname.find('Linear') != -1 or classname.find('Bilinear') != -1:",
            "\t\tnn.init.${1|kaiming_uniform_(a=2\\, mode='fan_in'\\, nonlinearity='leaky_relu'\\, ,kaiming_normal_(a=0\\, mode='fan_in'\\, nonlinearity='leaky_relu'\\, ,xavier_uniform_(gain=1\\, ,xavier_normal_(gain=1\\, ,eye_(,orthogonal_(gain=1\\, ,normal_(mean=0\\, std=1\\, ,uniform_(a=0\\, b=1\\, ,sparse_(sparsity=0.1\\, std=0.01\\, ,constant_(val=0.1\\, ,zeros_(,ones_(|}tensor=m.weight)",
            "\t\tif m.bias: nn.init.${2|zeros(,uniform_(a=0\\, b=1\\, ,normal_(mean=0\\, std=1\\, ,ones_(,constant_(val=0.01\\, |}tensor=m.bias)",
            "",
            "\telif classname.find('Conv') != -1:",
            "\t\tnn.init.${3|kaiming_uniform_(a=2\\, mode='fan_in'\\, nonlinearity='leaky_relu'\\, ,kaiming_normal_(a=0\\, mode='fan_in'\\, nonlinearity='leaky_relu'\\, ,xavier_uniform_(gain=1\\, ,xavier_normal_(gain=1\\, ,dirac_(,orthogonal_(gain=1\\, ,normal_(mean=0\\, std=1\\, ,uniform_(a=0\\, b=1\\, ,sparse_(sparsity=0.1\\, std=0.01\\, ,constant_(val=0.1\\, ,zeros_(,ones_(|}tensor=m.weight)",
            "\t\tif m.bias: nn.init.${4|zeros(,normal_(mean=0\\, std=1\\, ,uniform_(a=0\\, b=1\\, ,ones_(,constant_(val=0.01\\, |}tensor=m.bias)",
            "",
            "\telif classname.find('BatchNorm') != -1 or classname.find('GroupNorm') != -1 or classname.find('LayerNorm') != -1:",
            "\t\tnn.init.${5|uniform_(a=0\\, b=1\\, ,normal_(mean=0\\, std=1\\, ,constant_(val=0.1\\, ,zeros_(,ones_(|}tensor=m.weight)",
            "\t\tnn.init.${6|zeros(,normal_(mean=0\\, std=1\\, ,uniform_(a=0\\, b=1\\, ,ones_(,constant_(val=0.01\\, |}tensor=m.bias)",
            "",
            "\telif classname.find('Cell') != -1:",
            "\t\tnn.init.${7|xavier_uniform_(gain=1\\, ,xavier_normal_(gain=1\\, ,kaiming_uniform_(a=0\\, mode='fan_in'\\, nonlinearity='leaky_relu'\\, ,kaiming_normal_(a=0\\, mode='fan_in'\\, nonlinearity='leaky_relu'\\, ,eye_(,orthogonal_(gain=1\\, ,normal_(mean=0\\, std=1\\, ,uniform_(a=0\\, b=1\\, ,sparse_(sparsity=0.1\\, std=0.01\\, ,constant_(val=0.1\\, ,zeros_(,ones_(|}tensor=m.weight_hh)",
            "\t\tnn.init.${8|xavier_uniform_(gain=1\\, ,xavier_normal_(gain=1\\, ,kaiming_uniform_(a=0\\, mode='fan_in'\\, nonlinearity='leaky_relu'\\, ,kaiming_normal_(a=0\\, mode='fan_in'\\, nonlinearity='leaky_relu'\\, ,eye_(,orthogonal_(gain=1\\, ,normal_(mean=0\\, std=1\\, ,uniform_(a=0\\, b=1\\, ,sparse_(sparsity=0.1\\, std=0.01\\, ,constant_(val=0.1\\, ,zeros_(,ones_(|}tensor=m.weight_ih)",
            "\t\tnn.init.${9|ones_(,normal_(mean=0\\, std=1\\, ,uniform_(a=0\\, b=1\\, ,zeros(,constant_(val=0.01\\, |}tensor=m.bias_hh)",
            "\t\tnn.init.${10|ones_(,normal_(mean=0\\, std=1\\, ,uniform_(a=0\\, b=1\\, ,zeros(,constant_(val=0.01\\, |}tensor=m.bias_ih)",
            "",
            "\telif classname.find('RNN') != -1 or classname.find('LSTM') != -1 or classname.find('GRU') != -1:",
            "\t\tfor w in m.all_weights:",
            "\t\t\tnn.init.${11|xavier_uniform_(gain=1\\, ,xavier_normal_(gain=1\\, ,kaiming_uniform_(a=0\\, mode='fan_in'\\, nonlinearity='leaky_relu'\\, ,kaiming_normal_(a=0\\, mode='fan_in'\\, nonlinearity='leaky_relu'\\, ,eye_(,orthogonal_(gain=1\\, ,normal_(mean=0\\, std=1\\, ,uniform_(a=0\\, b=1\\, ,sparse_(sparsity=0.1\\, std=0.01\\, ,constant_(val=0.1\\, ,zeros_(,ones_(|}tensor=w[2].data)",
            "\t\t\tnn.init.${12|xavier_uniform_(gain=1\\, ,xavier_normal_(gain=1\\, ,kaiming_uniform_(a=0\\, mode='fan_in'\\, nonlinearity='leaky_relu'\\, ,kaiming_normal_(a=0\\, mode='fan_in'\\, nonlinearity='leaky_relu'\\, ,eye_(,orthogonal_(gain=1\\, ,normal_(mean=0\\, std=1\\, ,uniform_(a=0\\, b=1\\, ,sparse_(sparsity=0.1\\, std=0.01\\, ,constant_(val=0.1\\, ,zeros_(,ones_(|}tensor=w[3].data)",
            "\t\t\tnn.init.${13|ones_(,normal_(mean=0\\, std=1\\, ,uniform_(a=0\\, b=1\\, ,zeros(,constant_(val=0.01\\, |}tensor=w[0].data)",
            "\t\t\tnn.init.${14|ones_(,normal_(mean=0\\, std=1\\, ,uniform_(a=0\\, b=1\\, ,zeros(,constant_(val=0.01\\, |}tensor=w[1].data)",
            "",
            "\tif classname.find('Embedding') != -1:",
            "\t\tnn.init.${1|normal_(mean=0\\, std=1\\, ,xavier_uniform_(gain=1\\, ,xavier_normal_(gain=1\\, ,kaiming_uniform_(a=0\\, mode='fan_in'\\, nonlinearity='leaky_relu'\\, ,kaiming_normal_(a=0\\, mode='fan_in'\\, nonlinearity='leaky_relu'\\, ,eye_(,orthogonal_(gain=1\\, ,uniform_(a=0\\, b=1\\, ,sparse_(sparsity=0.1\\, std=0.01\\, ,constant_(val=0.1\\, ,zeros_(,ones_(|}tensor=m.weight)",
            "",
            "${15:net}.apply(init_weights)"
        ]
    },
    "Train Loop": {
        "prefix": "pytorch:train",
        "description": "Example for creating a simple training loop",
        "body":[
            "# loop over the dataset multiple times",
            "for epoch in range(${1:5}):",
            "\trunning_loss = 0.0",
            "\tfor i, data in enumerate(${2:trainloader}, 0):",
            "\t\tinputs, labels = data",
            "\t\tinputs, labels = inputs.to(${3:device}), labels.to(${3:device})",
            "",
            "\t\t# zero the parameter gradients",
            "\t\t${4:optimizer}.zero_grad()",
            "",
            "\t\t# forward + backward + optimize",
            "\t\toutputs = ${5:net}(inputs)",
            "\t\tloss = ${6:criterion}(outputs, labels)",
            "\t\tloss.backward()",
            "\t\t${4:optimizer}.step()",
            "",
            "\t\trunning_loss += loss.item()",
            "",
            "\tprint('Loss: {}'.format(running_loss))",
            "",
            "print('Finished Training')"
        ]
    },
    "Model Checkpoint": {
        "prefix": "pytorch:checkpoint",
        "desription": "Load model from checkpoint",
        "body": [
            "${1:model}.load_state_dict(${2|'path/to/model',torch.hub.load_state_dict_from_url('url')|})"
        ]
    },
    "GitHub Checkpoint": {
        "prefix": "pytorch:github",
        "desription": "Load model from github repository",
        "body": [
            "${1:model} = torch.hub.load(github=${2:'pytorch/vision'}, model=${3:'resnet50'}, pretrained=${4|False,True|})"
        ]
    },
    "Freeze Layers": {
        "prefix": "pytorch:freeze",
        "desription": "Freeze all layers of the network",
        "body": [
            "for params in ${1:net}.parameters():",
            "\tparams.require_grad = False"
        ]
    },
    "Sampler": {
        "prefix": "pytorch:sampler",
        "desription": "Specifies an batch sampler",
        "body": [
            "sampler = torch.utils.data.${1|Sampler(data_source),SequantialSample(data_source),RandomSampler(data_source),SubsetRandomSampler(indicies),WeightedRandomSampler(weights\\, num_samples),BatchSampler(sampler\\, batch_size\\, drop_last),distributed.DistributedSampler(dataset)|}"
        ]
    },
    "Unfreeze Layers":{
        "prefix": "pytorch:unfreeze",
        "desription": "Unfreeze all layers of the network",
        "body": [
            "for params in ${1:net}.parameters():",
            "\tparams.require_grad = True"
        ]
    },
    "Activation":{
        "prefix": "pytorch:layer:activation",
        "description": "Adds a non-linear activation",
        "body": [
            "${1:nonlin} = nn.${2|ELU(alpha=1.\\, inplace=False),Hardshrink(lambd=0.5),Hardtanh(min_val=-1\\, max_val=1\\, inplace=False\\, min_value=None\\, max_value=None),LeakyReLU(negative_slope=0.01\\, inplace=False),LogSigmoid,PReLU(num_parameters=1\\, init=0.25),ReLU(inplace=False),ReLU6(inplace=False),RReLU(lower=0.125\\, upper=0.3333333333333333\\, inplace=False),CELU(alpha=1.0\\, inplace=False),SELU(inplace=False),Sigmoid,Softplus(beta=1\\, threshold=20),Softshrink(lambd=0.5),Softsign,Tanh,Tanhshrink,Threshold(threshold\\, value\\, inplace=False),Softmin(dim=None),Softmax(dim=None),Softmax2d,LogSoftmax(dim=None),AdaptiveLogSoftmaxWithLogits(in_features\\, n_classes\\, cutoffs\\, div_value=4.0\\, head_bias=True)|}"
        ]
    },
    "Attention":{
        "prefix": "pytorch:layer:attention",
        "description": "Adds an attention layer",
        "body": [
            "${1:mutli_attention} = nn.MultiheadAttention(embed_dim=$2, num_heads=$3)"
        ]
    },
    "Convolution Layer":{
        "prefix": "pytorch:layer:conv",
        "description": "Creates a convolutional layer",
        "body": [
            "${1:conv} = nn.${2|Conv1d(in_channel\\, out_channel\\, groups=1\\, bias=True\\, ,Conv2d(in_channel\\, out_channel\\, groups=1\\, bias=True\\, ,Conv3d(in_channel\\, out_channel\\, groups=1\\, bias=True\\, ,ConvTranspose1d(in_channel\\, out_channel\\, groups=1\\, bias=True\\, out_padding=0\\, dilation=1\\, ,ConvTranspose2d/in_channel\\, out_channel\\, groups=1\\, bias=True\\, out_padding=0\\, dilation=1\\, ,ConvTranspose3d(in_channel\\, out_channel\\, groups=1\\, bias=True\\, out_padding=0\\, dilation=1\\, ,Unfold(dilation=1\\, ,Fold(output_size\\, |}kernel_size=2, padding=0, stride=1)"
        ]
    },
    "Pooling Layer":{
        "prefix": "pytorch:layer:pooling",
        "description": "Creates a pooling layer",
        "body": [
            "${1:pool} = nn.${2|MaxPool1d(kernel_size\\, stride=None\\, padding=0\\, dilation=1\\, return_indices=False\\, ceil_mode=False),MaxPool2d(kernel_size\\, stride=None\\, padding=0\\, dilation=1\\, return_indices=False\\, ceil_mode=False),MaxPool3d(kernel_size\\, stride=None\\, padding=0\\, dilation=1\\, return_indices=False\\, ceil_mode=False),MaxUnpool1d(kernel_size\\, stride=None\\, padding=0),MaxUnpool2d(kernel_size\\, stride=None\\, padding=0),MaxUnpool3d(kernel_size\\, stride=None\\, padding=0),AvgPool1d(kernel_size\\, stride=None\\, padding=0\\, ceil_mode=False\\, count_include_pad=True),AvgPool2d(kernel_size\\, stride=None\\, padding=0\\, ceil_mode=False\\, count_include_pad=True),AvgPool3d(kernel_size\\, stride=None\\, padding=0\\, ceil_mode=False\\, count_include_pad=True),FractionalMaxPool2d(kernel_size\\, output_size=None\\, output_ratio=None\\, return_indices=False\\, random_samples=None),LPPool1d(norm_type\\, kernel_size\\, stride=None\\, ceil_mode=False),LPPool2d(norm_type\\, kernel_size\\, stride=None\\, ceil_mode=False),AdaptiveMaxPool1d(output_size\\, return_indices=False),AdaptiveMaxPool2d(output_size\\, return_indices=False),AdaptiveMaxPool3d(output_size\\, return_indices=False),AdaptiveAvgPool1d(output_size),AdaptiveAvgPool2d(output_size),AdaptiveAvgPool3d(output_size)|}"
        ]
    },
    "Padding Layer":{
        "prefix": "pytorch:layer:padding",
        "description": "Creates a padding layer",
        "body": [
            "${1:padding} = nn.${2|ReflectionPad1d(,ReflectionPad2d(,ReplicationPad1d(,ReplicationPad2d(,ReplicationPad3d(,ZeroPad2d(,ConstantPad1d(value=3.5\\, ,ConstantPad2d(value=3.5\\, ,ConstantPad3d(value=3.5\\, |}padding=${3:(2,2)}"
        ]
    },
    "Recurrent Layer":{
        "prefix": "pytorch:layer:recurrent",
        "description": "Creates a recurrent layer",
        "body": [
            "${1:recurrent} = nn.${2|RNN,LSTM,GRU,RNNCell,LSTMCell,GRUCell|}(${3:input_size}, ${4:hidden_size}, bias=${5:True})"
        ]
    },
    "Normalization Layer":{
        "prefix": "pytorch:layer:norm",
        "description": "Creates a normalization layer",
        "body": [
            "${1:norm} = nn.${2|BatchNorm1d(num_features\\, eps=1e-5\\, momentum=0.1\\, affine=True\\, track_running_stats=True),BatchNorm2d(num_features\\, eps=1e-5\\, momentum=0.1\\, affine=True\\, track_running_stats=True),BatchNorm3d(num_features\\, eps=1e-5\\, momentum=0.1\\, affine=True\\, track_running_stats=True),GroupNorm(num_groups\\, num_channels\\, eps=1e-5\\, affine=True),SyncBatchNorm(num_features\\, eps=1e-05\\, momentum=0.1\\, affine=True),InstanceNorm1d(num_features\\, eps=1e-5\\, momentum=0.1\\, affine=False\\, track_running_stats=False),InstanceNorm2d(num_features\\, eps=1e-5\\, momentum=0.1\\, affine=False\\, track_running_stats=False),InstanceNorm3d(num_features\\, eps=1e-5\\, momentum=0.1\\, affine=False\\, track_running_stats=False),LayerNorm(normalized_shape\\, eps=1e-5\\, elementwise_affine=True),LocalResponseNorm(size\\, alpha=1e-4\\, beta=0.75\\, k=1)|}"
        ]
    },
    "Linear Layer":{
        "prefix": "pytorch:layer:linear",
        "description": "Creates a linear layer",
        "body": [
            "${1:linear} = nn.${2|Identity(,Linear(in_feature\\, ,Bilinear(in_features1\\, in_features2\\, |}out_features, bias=True)"
        ]
    },
    "Dropout":{
        "prefix": "pytorch:layer:dropout",
        "description": "Adds dropout",
        "body": [
            "${1:drop} = nn.${2|Dropout,Dropout2d,Dropout3d,AlphaDropout|}(p=${3:0.5}, inplace=${4|False,True|})"
        ]
    },
    "Sparse Layer":{
        "prefix": "pytorch:layer:sparse",
        "description": "Creates a sparse layer",
        "body": [
            "${1:sparse} = nn.${2|Embedding,EmbeddingBag|}(${3:num_embeddings}, ${4:embedding_dim})"
        ]
    },
    "Vision Layer":{
        "prefix": "pytorch:layer:vision",
        "description": "Creates a vision layer",
        "body": [
            "${1:vision} = nn.${2|PixelShuffle(upscale_factor),Upsample(size=None\\, scale_factor=None\\, mode='nearest'\\, align_corners=None),UpsamplingNearest2d(size=None\\, scale_factor=None),UpsamplingBilinear2d(size=None\\, scale_factor=None)|}"
        ]
    },
    "Distance Layer": {
        "prefix": "pytorch:layer:distance",
        "description": "Creates a distance layer",
        "body": [
            "${1:distance} = nn.${2|CosineSimilarity,PairwiseDistance|}()"
        ]
    },
    "Activation Function":{
        "prefix": "pytorch:F:activation",
        "description": "Applies a nonlinearity function",
        "body": [
            "F.${1|threshold(input\\, threshold\\, value\\, inplace=False),relu(input\\, inplace=False),relu6(input\\, inplace=False),hardtanh(input\\, min_val=-1.\\, max_val=1.\\, inplace=False),elu(input\\, alpha=1.0\\, inplace=False),selu(input\\, inplace=False),celu(input\\, alpha=1.\\, inplace=False),leaky_relu(input\\, negative_slope=0.01\\, inplace=False),prelu(input\\, weight),rrelu(input\\, lower=1./8\\, upper=1./3\\, training=False\\, inplace=False),glu(input\\, dim=-1),logsigmoid(input),hardshrink(input\\, lambd=0.5),tanhshrink(input),softsign(input),softplus(input\\, beta=1\\, threshold=20),softmin(input\\, dim=None\\, _stacklevel=3),softmax(input\\, dim=None\\, _stacklevel=3),softshrink(input\\, lambd=0.5),gumbel_softmax(logits\\, tau=1\\, hard=False\\, eps=1e-10),log_softmax(input\\, dim=None\\, _stacklevel=3),tanh(input),sigmoid(input)|}"
        ]
    },
    "Convolution Function":{
        "prefix": "pytorch:F:conv",
        "description": "Applies a convolution function",
        "body": [
            "F.${1|conv1d,conv2d,conv3d,conv_transpose1d,conv_transpose2d,conv_transpose3d|}(${2:input}, ${3:weight}, bias=None, stride=1, padding=0)"
        ]
    },
    "Pooling Function":{
        "prefix": "pytorch:F:pooling",
        "description": "Applies a pooling function",
        "body": [
            "F.${1|avg_pool1d(input\\, kernel_size\\, stride=None\\, padding=0),avg_pool2d(input\\, kernel_size\\, stride=None\\, padding=0),avg_pool3d(input\\, kernel_size\\, stride=None\\, padding=0),max_pool1d(input\\, kernel_size\\, stride=None\\, padding=0),max_pool2d(input\\, kernel_size\\, stride=None\\, padding=0,max_pool3d(input\\, kernel_size\\, stride=None\\, padding=0),max_unpool1d(input\\, indices\\, kernel_size\\, stride=None\\, padding=0),max_unpool2d(input\\, indices\\, kernel_size\\, stride=None\\, padding=0),max_unpool3d(input\\, indices\\, kernel_size\\, stride=None\\, padding=0),lp_pool1d(input\\, norm_type\\, kernel_size\\, stride=None),lp_pool2d(input\\, norm_type\\, kernel_size\\, stride=None),adaptive_max_pool1d(input\\, output_size),adaptive_max_pool2d(input\\, output_size),adaptive_max_pool3d(input\\, output_size),adaptive_avg_pool1d(input\\, output_size),adaptive_avg_pool2d(input\\, output_size),adaptive_avg_pool3d(input\\, output_size)|}"
        ]
    },
    "Normalization Function":{
        "prefix": "pytorch:F:norm",
        "description": "Applies a normalization function",
        "body": [
            "F.${1|batch_norm(input\\, running_mean\\, running_var),instance_norm(input\\, running_mean=None\\, running_var=None),layer_norm(input\\, normalized_shape),local_response_norm(input\\, size),normalize(input)|}"
        ]
    },
    "Linear Function":{
        "prefix": "pytorch:F:linear",
        "description": "Applies a linear function",
        "body": [
            "F.${1|linear(input\\, weight),bilinear(input1\\, input2\\, weight)|}"
        ]
    },
    "Dropout Function":{
        "prefix": "pytorch:F:dropout",
        "description": "Applies a dropout function",
        "body": [
            "F.${1|dropout,dropout2d,dropout3d,alpha_dropout|}(${2:input}, p=${3:0.5})"
        ]
    },
    "Sparse Function":{
        "prefix": "pytorch:F:sparse",
        "description": "Applies an embedding function",
        "body": [
            "F.${1|embedding,embedding_bag|}(${2:input}, ${3:weight})"
        ]
    },
    "One Hot Encoding":{
        "prefix": "pytorch:F:one_hot",
        "description": "Applies an one hot encoding function",
        "body": [
            "F.one_hot(${1:tensor}, num_classes=${2:0})"
        ]
    },
    "Distance Function":{
        "prefix": "pytorch:F:distance",
        "description": "Applies a distance function",
        "body": [
            "F.${1|pairwise_distance,cosine_similarity|}(${2:x1}, ${3:x2})"
        ]
    },
    "Vision Function": {
        "prefix": "pytorch:F:vision",
        "description": "Applies a vision function",
        "body": [
            "F.${1|pixel_shuffle(input\\, upscale_factor),pad(input\\, pad),interpolate(input\\, size=None\\, scale_factor=None\\, mode='nearest'\\, align_corners=None),grid_sample(input\\, grid),affine_grid(theta\\, size)|}"
        ]
    },
    "Loss Function": {
        "prefix": "pytorch:F:loss",
        "description": "Applies a loss function",
        "body": [
            "F.${1|cross_entropy,binary_cross_entropy,binary_cross_entropy_with_logits,poisson_nll_loss,hinge_embedding_loss,kl_div,l1_loss,smooth_l1_loss,mse_loss,multilabel_margin_loss,multilabel_soft_margin_loss,multi_margin_loss,nll_loss,soft_margin_loss|}(${2:input}, ${3:target})"
        ]
    },
    "Resnet Basic Block":{
        "prefix": "pytorch:layer:resnet:block",
        "description": "Creates a Resnet basic block",
        "body": [
            "class BasicBlock(nn.Module):",
            "\t# see https://pytorch.org/docs/0.4.0/_modules/torchvision/models/resnet.html",
            "\tdef __init__(self, inplanes, planes, stride=1):",
            "\t\tsuper(BasicBlock, self).__init__()",
            "\t\tself.conv1 = nn.Conv2d(inplanes, planes, kernel_size=3, stride=stride, padding=1, bias=False)",
            "\t\tself.bn1 = nn.BatchNorm2d(planes)",
            "\t\tself.relu = nn.ReLU(inplace=True)",
            "\t\tself.conv2 = nn.Conv2d(planes, planes, kernel_size=3, padding=1, bias=False)",
            "\t\tself.bn2 = nn.BatchNorm2d(planes)",
            "",
            "\tdef forward(self, x):",
            "\t\tresidual = x",
            "\t\tout = self.conv1(x)",
            "\t\tout = self.bn1(out)",
            "\t\tout = self.relu(out)",
            "\t\tout = self.conv2(out)",
            "\t\tout = self.bn2(out)",
            "\t\tout += residual",
            "\t\tout = self.relu(out)",
            "\t\treturn out"
        ]
    },
    "Resnet Bottleneck Block":{
        "prefix": "pytorch:layer:resnet:bottleneck",
        "description": "Creates a Resnet bottleneck block",
        "body": [
            "class Bottleneck(nn.Module):",
            "\t# see https://pytorch.org/docs/0.4.0/_modules/torchvision/models/resnet.html ",
            "\tdef __init__(self, inplanes, planes, stride=1, downsample=None):",
            "\t\tsuper(Bottleneck, self).__init__()",
            "\t\tself.conv1 = nn.Conv2d(inplanes, planes, kernel_size=1, stride=stride, bias=False)",
            "\t\tself.bn1 = nn.BatchNorm2d(planes)",
            "\t\tself.conv2 = nn.Conv2d(planes, planes, kernel_size=3, stride=1, padding=1, bias=False)",
            "\t\tself.bn2 = nn.BatchNorm2d(planes)",
            "\t\tself.conv3 = nn.Conv2d(planes, planes * 4, kernel_size=1, bias=False)",
            "\t\tself.bn3 = nn.BatchNorm2d(planes * 4)",
            "\t\tself.relu = nn.ReLU(inplace=True)",
            "",
            "\tdef forward(self, x):",
            "\t\tresidual = x",
            "\t\tout = self.conv1(x)",
            "\t\tout = self.bn1(out)",
            "\t\tout = self.relu(out)",
            "\t\tout = self.conv2(out)",
            "\t\tout = self.bn2(out)",
            "\t\tout = self.relu(out)",
            "\t\tout = self.conv3(out)",
            "\t\tout = self.bn3(out)",
            "\t\tout += residual",
            "\t\tout = self.relu(out)",
            "\t\treturn out"
        ]
    },
    "Imagenet Example": {
        "prefix": "pytorch:examples:imagenet",
        "description": "Imagenet code example",
        "body": [
            "import argparse",
            "import os",
            "import random",
            "import shutil",
            "import time",
            "import warnings",
            "",
            "import torch",
            "import torch.nn as nn",
            "import torch.nn.parallel",
            "import torch.backends.cudnn as cudnn",
            "import torch.distributed as dist",
            "import torch.optim",
            "import torch.multiprocessing as mp",
            "import torch.utils.data",
            "import torch.utils.data.distributed",
            "import torchvision.transforms as transforms",
            "import torchvision.datasets as datasets",
            "import torchvision.models as models",
            "",
            "model_names = sorted(name for name in models.__dict__",
            "\tif name.islower() and not name.startswith(\"__\")",
            "\tand callable(models.__dict__[name]))",
            "",
            "parser = argparse.ArgumentParser(description='PyTorch ImageNet Training')",
            "parser.add_argument('data', metavar='DIR',",
            "\t\t\t\t\thelp='path to dataset')",
            "parser.add_argument('-a', '--arch', metavar='ARCH', default='resnet18',",
            "\t\t\t\t\tchoices=model_names,",
            "\t\t\t\t\thelp='model architecture: ' +",
            "\t\t\t\t\t\t' | '.join(model_names) +",
            "\t\t\t\t\t\t' (default: resnet18)')",
            "parser.add_argument('-j', '--workers', default=4, type=int, metavar='N',",
            "\t\t\t\t\thelp='number of data loading workers (default: 4)')",
            "parser.add_argument('--epochs', default=90, type=int, metavar='N',",
            "\t\t\t\t\thelp='number of total epochs to run')",
            "parser.add_argument('--start-epoch', default=0, type=int, metavar='N',",
            "\t\t\t\t\thelp='manual epoch number (useful on restarts)')",
            "parser.add_argument('-b', '--batch-size', default=256, type=int,",
            "\t\t\t\t\tmetavar='N',",
            "\t\t\t\t\thelp='mini-batch size (default: 256), this is the total '",
            "\t\t\t\t\t\t 'batch size of all GPUs on the current node when '",
            "\t\t\t\t\t\t 'using Data Parallel or Distributed Data Parallel')",
            "parser.add_argument('--lr', '--learning-rate', default=0.1, type=float,",
            "\t\t\t\t\tmetavar='LR', help='initial learning rate', dest='lr')",
            "parser.add_argument('--momentum', default=0.9, type=float, metavar='M',",
            "\t\t\t\t\thelp='momentum')",
            "parser.add_argument('--wd', '--weight-decay', default=1e-4, type=float,",
            "\t\t\t\t\tmetavar='W', help='weight decay (default: 1e-4)',",
            "\t\t\t\t\tdest='weight_decay')",
            "parser.add_argument('-p', '--print-freq', default=10, type=int,",
            "\t\t\t\t\tmetavar='N', help='print frequency (default: 10)')",
            "parser.add_argument('--resume', default='', type=str, metavar='PATH',",
            "\t\t\t\t\thelp='path to latest checkpoint (default: none)')",
            "parser.add_argument('-e', '--evaluate', dest='evaluate', action='store_true',",
            "\t\t\t\t\thelp='evaluate model on validation set')",
            "parser.add_argument('--pretrained', dest='pretrained', action='store_true',",
            "\t\t\t\t\thelp='use pre-trained model')",
            "parser.add_argument('--world-size', default=-1, type=int,",
            "\t\t\t\t\thelp='number of nodes for distributed training')",
            "parser.add_argument('--rank', default=-1, type=int,",
            "\t\t\t\t\thelp='node rank for distributed training')",
            "parser.add_argument('--dist-url', default='tcp://224.66.41.62:23456', type=str,",
            "\t\t\t\t\thelp='url used to set up distributed training')",
            "parser.add_argument('--dist-backend', default='nccl', type=str,",
            "\t\t\t\t\thelp='distributed backend')",
            "parser.add_argument('--seed', default=None, type=int,",
            "\t\t\t\t\thelp='seed for initializing training. ')",
            "parser.add_argument('--gpu', default=None, type=int,",
            "\t\t\t\t\thelp='GPU id to use.')",
            "parser.add_argument('--multiprocessing-distributed', action='store_true',",
            "\t\t\t\t\thelp='Use multi-processing distributed training to launch '",
            "\t\t\t\t\t\t 'N processes per node, which has N GPUs. This is the '",
            "\t\t\t\t\t\t 'fastest way to use PyTorch for either single node or '",
            "\t\t\t\t\t\t 'multi node data parallel training')",
            "",
            "best_acc1 = 0",
            "",
            "",
            "def main():",
            "\targs = parser.parse_args()",
            "",
            "\tif args.seed is not None:",
            "\t\trandom.seed(args.seed)",
            "\t\ttorch.manual_seed(args.seed)",
            "\t\tcudnn.deterministic = True",
            "\t\twarnings.warn('You have chosen to seed training. '",
            "\t\t\t\t\t  'This will turn on the CUDNN deterministic setting, '",
            "\t\t\t\t\t  'which can slow down your training considerably! '",
            "\t\t\t\t\t  'You may see unexpected behavior when restarting '",
            "\t\t\t\t\t  'from checkpoints.')",
            "",
            "\tif args.gpu is not None:",
            "\t\twarnings.warn('You have chosen a specific GPU. This will completely '",
            "\t\t\t\t\t  'disable data parallelism.')",
            "",
            "\tif args.dist_url == \"env://\" and args.world_size == -1:",
            "\t\targs.world_size = int(os.environ[\"WORLD_SIZE\"])",
            "",
            "\targs.distributed = args.world_size > 1 or args.multiprocessing_distributed",
            "",
            "\tngpus_per_node = torch.cuda.device_count()",
            "\tif args.multiprocessing_distributed:",
            "\t\t# Since we have ngpus_per_node processes per node, the total world_size",
            "\t\t# needs to be adjusted accordingly",
            "\t\targs.world_size = ngpus_per_node * args.world_size",
            "\t\t# Use torch.multiprocessing.spawn to launch distributed processes: the",
            "\t\t# main_worker process function",
            "\t\tmp.spawn(main_worker, nprocs=ngpus_per_node, args=(ngpus_per_node, args))",
            "\telse:",
            "\t\t# Simply call main_worker function",
            "\t\tmain_worker(args.gpu, ngpus_per_node, args)",
            "",
            "",
            "def main_worker(gpu, ngpus_per_node, args):",
            "\tglobal best_acc1",
            "\targs.gpu = gpu",
            "",
            "\tif args.gpu is not None:",
            "\t\tprint(\"Use GPU: {} for training\".format(args.gpu))",
            "",
            "\tif args.distributed:",
            "\t\tif args.dist_url == \"env://\" and args.rank == -1:",
            "\t\t\targs.rank = int(os.environ[\"RANK\"])",
            "\t\tif args.multiprocessing_distributed:",
            "\t\t\t# For multiprocessing distributed training, rank needs to be the",
            "\t\t\t# global rank among all the processes",
            "\t\t\targs.rank = args.rank * ngpus_per_node + gpu",
            "\t\tdist.init_process_group(backend=args.dist_backend, init_method=args.dist_url,",
            "\t\t\t\t\t\t\t\tworld_size=args.world_size, rank=args.rank)",
            "\t# create model",
            "\tif args.pretrained:",
            "\t\tprint(\"=> using pre-trained model '{}'\".format(args.arch))",
            "\t\tmodel = models.__dict__[args.arch](pretrained=True)",
            "\telse:",
            "\t\tprint(\"=> creating model '{}'\".format(args.arch))",
            "\t\tmodel = models.__dict__[args.arch]()",
            "",
            "\tif args.distributed:",
            "\t\t# For multiprocessing distributed, DistributedDataParallel constructor",
            "\t\t# should always set the single device scope, otherwise,",
            "\t\t# DistributedDataParallel will use all available devices.",
            "\t\tif args.gpu is not None:",
            "\t\t\ttorch.cuda.set_device(args.gpu)",
            "\t\t\tmodel.cuda(args.gpu)",
            "\t\t\t# When using a single GPU per process and per",
            "\t\t\t# DistributedDataParallel, we need to divide the batch size",
            "\t\t\t# ourselves based on the total number of GPUs we have",
            "\t\t\targs.batch_size = int(args.batch_size / ngpus_per_node)",
            "\t\t\targs.workers = int((args.workers + ngpus_per_node - 1) / ngpus_per_node)",
            "\t\t\tmodel = torch.nn.parallel.DistributedDataParallel(model, device_ids=[args.gpu])",
            "\t\telse:",
            "\t\t\tmodel.cuda()",
            "\t\t\t# DistributedDataParallel will divide and allocate batch_size to all",
            "\t\t\t# available GPUs if device_ids are not set",
            "\t\t\tmodel = torch.nn.parallel.DistributedDataParallel(model)",
            "\telif args.gpu is not None:",
            "\t\ttorch.cuda.set_device(args.gpu)",
            "\t\tmodel = model.cuda(args.gpu)",
            "\telse:",
            "\t\t# DataParallel will divide and allocate batch_size to all available GPUs",
            "\t\tif args.arch.startswith('alexnet') or args.arch.startswith('vgg'):",
            "\t\t\tmodel.features = torch.nn.DataParallel(model.features)",
            "\t\t\tmodel.cuda()",
            "\t\telse:",
            "\t\t\tmodel = torch.nn.DataParallel(model).cuda()",
            "",
            "\t# define loss function (criterion) and optimizer",
            "\tcriterion = nn.CrossEntropyLoss().cuda(args.gpu)",
            "",
            "\toptimizer = torch.optim.SGD(model.parameters(), args.lr,",
            "\t\t\t\t\t\t\t\tmomentum=args.momentum,",
            "\t\t\t\t\t\t\t\tweight_decay=args.weight_decay)",
            "",
            "\t# optionally resume from a checkpoint",
            "\tif args.resume:",
            "\t\tif os.path.isfile(args.resume):",
            "\t\t\tprint(\"=> loading checkpoint '{}'\".format(args.resume))",
            "\t\t\tcheckpoint = torch.load(args.resume)",
            "\t\t\targs.start_epoch = checkpoint['epoch']",
            "\t\t\tbest_acc1 = checkpoint['best_acc1']",
            "\t\t\tif args.gpu is not None:",
            "\t\t\t\t# best_acc1 may be from a checkpoint from a different GPU",
            "\t\t\t\tbest_acc1 = best_acc1.to(args.gpu)",
            "\t\t\tmodel.load_state_dict(checkpoint['state_dict'])",
            "\t\t\toptimizer.load_state_dict(checkpoint['optimizer'])",
            "\t\t\tprint(\"=> loaded checkpoint '{}' (epoch {})\"",
            "\t\t\t\t  .format(args.resume, checkpoint['epoch']))",
            "\t\telse:",
            "\t\t\tprint(\"=> no checkpoint found at '{}'\".format(args.resume))",
            "",
            "\tcudnn.benchmark = True",
            "",
            "\t# Data loading code",
            "\ttraindir = os.path.join(args.data, 'train')",
            "\tvaldir = os.path.join(args.data, 'val')",
            "\tnormalize = transforms.Normalize(mean=[0.485, 0.456, 0.406],",
            "\t\t\t\t\t\t\t\t     std=[0.229, 0.224, 0.225])",
            "",
            "\ttrain_dataset = datasets.ImageFolder(",
            "\t\ttraindir,",
            "\t\ttransforms.Compose([",
            "\t\t\ttransforms.RandomResizedCrop(224),",
            "\t\t\ttransforms.RandomHorizontalFlip(),",
            "\t\t\ttransforms.ToTensor(),",
            "\t\t\tnormalize,",
            "\t\t]))",
            "",
            "\tif args.distributed:",
            "\t\ttrain_sampler = torch.utils.data.distributed.DistributedSampler(train_dataset)",
            "\telse:",
            "\t\ttrain_sampler = None",
            "",
            "\ttrain_loader = torch.utils.data.DataLoader(",
            "\t\ttrain_dataset, batch_size=args.batch_size, shuffle=(train_sampler is None),",
            "\t\tnum_workers=args.workers, pin_memory=True, sampler=train_sampler)",
            "",
            "\tval_loader = torch.utils.data.DataLoader(",
            "\t\tdatasets.ImageFolder(valdir, transforms.Compose([",
            "\t\t\ttransforms.Resize(256),",
            "\t\t\ttransforms.CenterCrop(224),",
            "\t\t\ttransforms.ToTensor(),",
            "\t\t\tnormalize,",
            "\t\t])),",
            "\t\tbatch_size=args.batch_size, shuffle=False,",
            "\t\tnum_workers=args.workers, pin_memory=True)",
            "",
            "\tif args.evaluate:",
            "\t\tvalidate(val_loader, model, criterion, args)",
            "\t\treturn",
            "",
            "\tfor epoch in range(args.start_epoch, args.epochs):",
            "\t\tif args.distributed:",
            "\t\t\ttrain_sampler.set_epoch(epoch)",
            "\t\tadjust_learning_rate(optimizer, epoch, args)",
            "",
            "\t\t# train for one epoch",
            "\t\ttrain(train_loader, model, criterion, optimizer, epoch, args)",
            "",
            "\t\t# evaluate on validation set",
            "\t\tacc1 = validate(val_loader, model, criterion, args)",
            "",
            "\t\t# remember best acc@1 and save checkpoint",
            "\t\tis_best = acc1 > best_acc1",
            "\t\tbest_acc1 = max(acc1, best_acc1)",
            "",
            "\t\tif not args.multiprocessing_distributed or (args.multiprocessing_distributed",
            "\t\t\t\tand args.rank % ngpus_per_node == 0):",
            "\t\t\tsave_checkpoint({",
            "\t\t\t\t'epoch': epoch + 1,",
            "\t\t\t\t'arch': args.arch,",
            "\t\t\t\t'state_dict': model.state_dict(),",
            "\t\t\t\t'best_acc1': best_acc1,",
            "\t\t\t\t'optimizer' : optimizer.state_dict(),",
            "\t\t\t}, is_best)",
            "",
            "",
            "def train(train_loader, model, criterion, optimizer, epoch, args):",
            "\tbatch_time = AverageMeter('Time', ':6.3f')",
            "\tdata_time = AverageMeter('Data', ':6.3f')",
            "\tlosses = AverageMeter('Loss', ':.4e')",
            "\ttop1 = AverageMeter('Acc@1', ':6.2f')",
            "\ttop5 = AverageMeter('Acc@5', ':6.2f')",
            "\tprogress = ProgressMeter(",
            "\t\tlen(train_loader),",
            "\t\t[batch_time, data_time, losses, top1, top5],",
            "\t\tprefix=\"Epoch: [{}]\".format(epoch))",
            "",
            "\t# switch to train mode",
            "\tmodel.train()",
            "",
            "\tend = time.time()",
            "\tfor i, (images, target) in enumerate(train_loader):",
            "\t\t# measure data loading time",
            "\t\tdata_time.update(time.time() - end)",
            "",
            "\t\tif args.gpu is not None:",
            "\t\t\timages = images.cuda(args.gpu, non_blocking=True)",
            "\t\ttarget = target.cuda(args.gpu, non_blocking=True)",
            "",
            "\t\t# compute output",
            "\t\toutput = model(images)",
            "\t\tloss = criterion(output, target)",
            "",
            "\t\t# measure accuracy and record loss",
            "\t\tacc1, acc5 = accuracy(output, target, topk=(1, 5))",
            "\t\tlosses.update(loss.item(), images.size(0))",
            "\t\ttop1.update(acc1[0], images.size(0))",
            "\t\ttop5.update(acc5[0], images.size(0))",
            "",
            "\t\t# compute gradient and do SGD step",
            "\t\toptimizer.zero_grad()",
            "\t\tloss.backward()",
            "\t\toptimizer.step()",
            "",
            "\t\t# measure elapsed time",
            "\t\tbatch_time.update(time.time() - end)",
            "\t\tend = time.time()",
            "",
            "\t\tif i % args.print_freq == 0:",
            "\t\t\tprogress.display(i)",
            "",
            "",
            "def validate(val_loader, model, criterion, args):",
            "\tbatch_time = AverageMeter('Time', ':6.3f')",
            "\tlosses = AverageMeter('Loss', ':.4e')",
            "\ttop1 = AverageMeter('Acc@1', ':6.2f')",
            "\ttop5 = AverageMeter('Acc@5', ':6.2f')",
            "\tprogress = ProgressMeter(",
            "\t\tlen(val_loader),",
            "\t\t[batch_time, losses, top1, top5],",
            "\t\tprefix='Test: ')",
            "",
            "\t# switch to evaluate mode",
            "\tmodel.eval()",
            "",
            "\twith torch.no_grad():",
            "\t\tend = time.time()",
            "\t\tfor i, (images, target) in enumerate(val_loader):",
            "\t\t\tif args.gpu is not None:",
            "\t\t\t\timages = images.cuda(args.gpu, non_blocking=True)",
            "\t\t\ttarget = target.cuda(args.gpu, non_blocking=True)",
            "",
            "\t\t\t# compute output",
            "\t\t\toutput = model(images)",
            "\t\t\tloss = criterion(output, target)",
            "",
            "\t\t\t# measure accuracy and record loss",
            "\t\t\tacc1, acc5 = accuracy(output, target, topk=(1, 5))",
            "\t\t\tlosses.update(loss.item(), images.size(0))",
            "\t\t\ttop1.update(acc1[0], images.size(0))",
            "\t\t\ttop5.update(acc5[0], images.size(0))",
            "",
            "\t\t\t# measure elapsed time",
            "\t\t\tbatch_time.update(time.time() - end)",
            "\t\t\tend = time.time()",
            "",
            "\t\t\tif i % args.print_freq == 0:",
            "\t\t\t\tprogress.display(i)",
            "",
            "\t\t# TODO: this should also be done with the ProgressMeter",
            "\t\tprint(' * Acc@1 {top1.avg:.3f} Acc@5 {top5.avg:.3f}'",
            "\t\t\t  .format(top1=top1, top5=top5))",
            "",
            "\treturn top1.avg",
            "",
            "",
            "def save_checkpoint(state, is_best, filename='checkpoint.pth.tar'):",
            "\ttorch.save(state, filename)",
            "\tif is_best:",
            "\t\tshutil.copyfile(filename, 'model_best.pth.tar')",
            "",
            "",
            "class AverageMeter(object):",
            "\t\"\"\"Computes and stores the average and current value\"\"\"",
            "\tdef __init__(self, name, fmt=':f'):",
            "\t\tself.name = name",
            "\t\tself.fmt = fmt",
            "\t\tself.reset()",
            "",
            "\tdef reset(self):",
            "\t\tself.val = 0",
            "\t\tself.avg = 0",
            "\t\tself.sum = 0",
            "\t\tself.count = 0",
            "",
            "\tdef update(self, val, n=1):",
            "\t\tself.val = val",
            "\t\tself.sum += val * n",
            "\t\tself.count += n",
            "\t\tself.avg = self.sum / self.count",
            "",
            "\tdef __str__(self):",
            "\t\tfmtstr = '{name} {val' + self.fmt + '} ({avg' + self.fmt + '})'",
            "\t\treturn fmtstr.format(**self.__dict__)",
            "",
            "",
            "class ProgressMeter(object):",
            "\tdef __init__(self, num_batches, meters, prefix=\"\"):",
            "\t\tself.batch_fmtstr = self._get_batch_fmtstr(num_batches)",
            "\t\tself.meters = meters",
            "\t\tself.prefix = prefix",
            "",
            "\tdef display(self, batch):",
            "\t\tentries = [self.prefix + self.batch_fmtstr.format(batch)]",
            "\t\tentries += [str(meter) for meter in self.meters]",
            "\t\tprint('\\t'.join(entries))",
            "",
            "\tdef _get_batch_fmtstr(self, num_batches):",
            "\t\tnum_digits = len(str(num_batches // 1))",
            "\t\tfmt = '{:' + str(num_digits) + 'd}'",
            "\t\treturn '[' + fmt + '/' + fmt.format(num_batches) + ']'",
            "",
            "",
            "def adjust_learning_rate(optimizer, epoch, args):",
            "\t\"\"\"Sets the learning rate to the initial LR decayed by 10 every 30 epochs\"\"\"",
            "\tlr = args.lr * (0.1 ** (epoch // 30))",
            "\tfor param_group in optimizer.param_groups:",
            "\t\tparam_group['lr'] = lr",
            "",
            "",
            "def accuracy(output, target, topk=(1,)):",
            "\t\"\"\"Computes the accuracy over the k top predictions for the specified values of k\"\"\"",
            "\twith torch.no_grad():",
            "\t\tmaxk = max(topk)",
            "\t\tbatch_size = target.size(0)",
            "",
            "\t\t_, pred = output.topk(maxk, 1, True, True)",
            "\t\tpred = pred.t()",
            "\t\tcorrect = pred.eq(target.view(1, -1).expand_as(pred))",
            "",
            "\t\tres = []",
            "\t\tfor k in topk:",
            "\t\t\tcorrect_k = correct[:k].view(-1).float().sum(0, keepdim=True)",
            "\t\t\tres.append(correct_k.mul_(100.0 / batch_size))",
            "\t\treturn res",
            "",
            "",
            "if __name__ == '__main__':",
            "\tmain()"
        ]
    },
    "Mnist Example": {
        "prefix": "pytorch:examples:mnist",
        "description": "Mnist code example",
        "body": [
            "from __future__ import print_function",
            "import argparse",
            "import torch",
            "import torch.nn as nn",
            "import torch.nn.functional as F",
            "import torch.optim as optim",
            "from torchvision import datasets, transforms",
            "",
            "",
            "class Net(nn.Module):",
            "\tdef __init__(self):",
            "\t\tsuper(Net, self).__init__()",
            "\t\tself.conv1 = nn.Conv2d(1, 20, 5, 1)",
            "\t\tself.conv2 = nn.Conv2d(20, 50, 5, 1)",
            "\t\tself.fc1 = nn.Linear(4*4*50, 500)",
            "\t\tself.fc2 = nn.Linear(500, 10)",
            "",
            "\tdef forward(self, x):",
            "\t\tx = F.relu(self.conv1(x))",
            "\t\tx = F.max_pool2d(x, 2, 2)",
            "\t\tx = F.relu(self.conv2(x))",
            "\t\tx = F.max_pool2d(x, 2, 2)",
            "\t\tx = x.view(-1, 4*4*50)",
            "\t\tx = F.relu(self.fc1(x))",
            "\t\tx = self.fc2(x)",
            "\t\treturn F.log_softmax(x, dim=1)",
            "   ",
            "def train(args, model, device, train_loader, optimizer, epoch):",
            "\tmodel.train()",
            "\tfor batch_idx, (data, target) in enumerate(train_loader):",
            "\t\tdata, target = data.to(device), target.to(device)",
            "\t\toptimizer.zero_grad()",
            "\t\toutput = model(data)",
            "\t\tloss = F.nll_loss(output, target)",
            "\t\tloss.backward()",
            "\t\toptimizer.step()",
            "\t\tif batch_idx % args.log_interval == 0:",
            "\t\t\tprint('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(",
            "\t\t\t\tepoch, batch_idx * len(data), len(train_loader.dataset),",
            "\t\t\t\t100. * batch_idx / len(train_loader), loss.item()))",
            "",
            "def test(args, model, device, test_loader):",
            "\tmodel.eval()",
            "\ttest_loss = 0",
            "\tcorrect = 0",
            "\twith torch.no_grad():",
            "\t\tfor data, target in test_loader:",
            "\t\t\tdata, target = data.to(device), target.to(device)",
            "\t\t\toutput = model(data)",
            "\t\t\ttest_loss += F.nll_loss(output, target, reduction='sum').item() # sum up batch loss",
            "\t\t\tpred = output.argmax(dim=1, keepdim=True) # get the index of the max log-probability",
            "\t\t\tcorrect += pred.eq(target.view_as(pred)).sum().item()",
            "",
            "\ttest_loss /= len(test_loader.dataset)",
            "",
            "\tprint('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(",
            "\t\ttest_loss, correct, len(test_loader.dataset),",
            "\t\t100. * correct / len(test_loader.dataset)))",
            "",
            "def main():",
            "\t# Training settings",
            "\tparser = argparse.ArgumentParser(description='PyTorch MNIST Example')",
            "\tparser.add_argument('--batch-size', type=int, default=64, metavar='N',",
            "\t\t\t\t\t\thelp='input batch size for training (default: 64)')",
            "\tparser.add_argument('--test-batch-size', type=int, default=1000, metavar='N',",
            "\t\t\t\t\t\thelp='input batch size for testing (default: 1000)')",
            "\tparser.add_argument('--epochs', type=int, default=10, metavar='N',",
            "\t\t\t\t\t\thelp='number of epochs to train (default: 10)')",
            "\tparser.add_argument('--lr', type=float, default=0.01, metavar='LR',",
            "\t\t\t\t\t\thelp='learning rate (default: 0.01)')",
            "\tparser.add_argument('--momentum', type=float, default=0.5, metavar='M',",
            "\t\t\t\t\t\thelp='SGD momentum (default: 0.5)')",
            "\tparser.add_argument('--no-cuda', action='store_true', default=False,",
            "\t\t\t\t\t\thelp='disables CUDA training')",
            "\tparser.add_argument('--seed', type=int, default=1, metavar='S',",
            "\t\t\t\t\t\thelp='random seed (default: 1)')",
            "\tparser.add_argument('--log-interval', type=int, default=10, metavar='N',",
            "\t\t\t\t\t\thelp='how many batches to wait before logging training status')",
            "   ",
            "\tparser.add_argument('--save-model', action='store_true', default=False,",
            "\t\t\t\t\t\thelp='For Saving the current Model')",
            "\targs = parser.parse_args()",
            "\tuse_cuda = not args.no_cuda and torch.cuda.is_available()",
            "",
            "\ttorch.manual_seed(args.seed)",
            "",
            "\tdevice = torch.device(\"cuda\" if use_cuda else \"cpu\")",
            "",
            "\tkwargs = {'num_workers': 1, 'pin_memory': True} if use_cuda else {}",
            "\ttrain_loader = torch.utils.data.DataLoader(",
            "\t\tdatasets.MNIST('../data', train=True, download=True,",
            "\t\t\t\t\t   transform=transforms.Compose([",
            "\t\t\t\t\t\t   transforms.ToTensor(),",
            "\t\t\t\t\t\t   transforms.Normalize((0.1307,), (0.3081,))",
            "\t\t\t\t\t   ])),",
            "\t\tbatch_size=args.batch_size, shuffle=True, **kwargs)",
            "\ttest_loader = torch.utils.data.DataLoader(",
            "\t\tdatasets.MNIST('../data', train=False, transform=transforms.Compose([",
            "\t\t\t\t\t\t   transforms.ToTensor(),",
            "\t\t\t\t\t\t   transforms.Normalize((0.1307,), (0.3081,))",
            "\t\t\t\t\t   ])),",
            "\t\tbatch_size=args.test_batch_size, shuffle=True, **kwargs)",
            "",
            "",
            "\tmodel = Net().to(device)",
            "\toptimizer = optim.SGD(model.parameters(), lr=args.lr, momentum=args.momentum)",
            "",
            "\tfor epoch in range(1, args.epochs + 1):",
            "\t\ttrain(args, model, device, train_loader, optimizer, epoch)",
            "\t\ttest(args, model, device, test_loader)",
            "",
            "\tif (args.save_model):",
            "\t\ttorch.save(model.state_dict(),\"mnist_cnn.pt\")",
            "\t   ",
            "if __name__ == '__main__':",
            "\tmain()"
        ]
    },
    "RL Example VPG": {
        "prefix": "pytorch:examples:vpg",
        "description": "VPG code example",
        "body": [
            "import argparse",
            "import gym",
            "import numpy as np",
            "from itertools import count",
            "",
            "import torch",
            "import torch.nn as nn",
            "import torch.nn.functional as F",
            "import torch.optim as optim",
            "from torch.distributions import Categorical",
            "",
            "",
            "parser = argparse.ArgumentParser(description='PyTorch REINFORCE example')",
            "parser.add_argument('--gamma', type=float, default=0.99, metavar='G',",
            "\t\t\t\t\thelp='discount factor (default: 0.99)')",
            "parser.add_argument('--seed', type=int, default=543, metavar='N',",
            "\t\t\t\t\thelp='random seed (default: 543)')",
            "parser.add_argument('--render', action='store_true',",
            "\t\t\t\t\thelp='render the environment')",
            "parser.add_argument('--log-interval', type=int, default=10, metavar='N',",
            "\t\t\t\t\thelp='interval between training status logs (default: 10)')",
            "args = parser.parse_args()",
            "",
            "",
            "env = gym.make('CartPole-v1')",
            "env.seed(args.seed)",
            "torch.manual_seed(args.seed)",
            "",
            "",
            "class Policy(nn.Module):",
            "\tdef __init__(self):",
            "\t\tsuper(Policy, self).__init__()",
            "\t\tself.affine1 = nn.Linear(4, 128)",
            "\t\tself.dropout = nn.Dropout(p=0.6)",
            "\t\tself.affine2 = nn.Linear(128, 2)",
            "",
            "\t\tself.saved_log_probs = []",
            "\t\tself.rewards = []",
            "",
            "\tdef forward(self, x):",
            "\t\tx = self.affine1(x)",
            "\t\tx = self.dropout(x)",
            "\t\tx = F.relu(x)",
            "\t\taction_scores = self.affine2(x)",
            "\t\treturn F.softmax(action_scores, dim=1)",
            "",
            "",
            "policy = Policy()",
            "optimizer = optim.Adam(policy.parameters(), lr=1e-2)",
            "eps = np.finfo(np.float32).eps.item()",
            "",
            "",
            "def select_action(state):",
            "\tstate = torch.from_numpy(state).float().unsqueeze(0)",
            "\tprobs = policy(state)",
            "\tm = Categorical(probs)",
            "\taction = m.sample()",
            "\tpolicy.saved_log_probs.append(m.log_prob(action))",
            "\treturn action.item()",
            "",
            "",
            "def finish_episode():",
            "\tR = 0",
            "\tpolicy_loss = []",
            "\treturns = []",
            "\tfor r in policy.rewards[::-1]:",
            "\t\tR = r + args.gamma * R",
            "\t\treturns.insert(0, R)",
            "\treturns = torch.tensor(returns)",
            "\treturns = (returns - returns.mean()) / (returns.std() + eps)",
            "\tfor log_prob, R in zip(policy.saved_log_probs, returns):",
            "\t\tpolicy_loss.append(-log_prob * R)",
            "\toptimizer.zero_grad()",
            "\tpolicy_loss = torch.cat(policy_loss).sum()",
            "\tpolicy_loss.backward()",
            "\toptimizer.step()",
            "\tdel policy.rewards[:]",
            "\tdel policy.saved_log_probs[:]",
            "",
            "",
            "def main():",
            "\trunning_reward = 10",
            "\tfor i_episode in count(1):",
            "\t\tstate, ep_reward = env.reset(), 0",
            "\t\tfor t in range(1, 10000):  # Don't infinite loop while learning",
            "\t\t\taction = select_action(state)",
            "\t\t\tstate, reward, done, _ = env.step(action)",
            "\t\t\tif args.render:",
            "\t\t\t\tenv.render()",
            "\t\t\tpolicy.rewards.append(reward)",
            "\t\t\tep_reward += reward",
            "\t\t\tif done:",
            "\t\t\t\tbreak",
            "",
            "\t\trunning_reward = 0.05 * ep_reward + (1 - 0.05) * running_reward",
            "\t\tfinish_episode()",
            "\t\tif i_episode % args.log_interval == 0:",
            "\t\t\tprint('Episode {}\\tLast reward: {:.2f}\\tAverage reward: {:.2f}'.format(",
            "\t\t\t\t  i_episode, ep_reward, running_reward))",
            "\t\tif running_reward > env.spec.reward_threshold:",
            "\t\t\tprint(\"Solved! Running reward is now {} and \"",
            "\t\t\t\t  \"the last episode runs to {} time steps!\".format(running_reward, t))",
            "\t\t\tbreak",
            "",
            "",
            "if __name__ == '__main__':",
            "\tmain()"
        ]
    },
    "RL Example Actor-Critic": {
        "prefix": "pytorch:examples:ac",
        "description": "Actor-Critic code example",
        "body": [
            "import argparse",
            "import gym",
            "import numpy as np",
            "from itertools import count",
            "from collections import namedtuple",
            "",
            "import torch",
            "import torch.nn as nn",
            "import torch.nn.functional as F",
            "import torch.optim as optim",
            "from torch.distributions import Categorical",
            "",
            "# Cart Pole",
            "",
            "parser = argparse.ArgumentParser(description='PyTorch actor-critic example')",
            "parser.add_argument('--gamma', type=float, default=0.99, metavar='G',",
            "\t\t\t\t\thelp='discount factor (default: 0.99)')",
            "parser.add_argument('--seed', type=int, default=543, metavar='N',",
            "\t\t\t\t\thelp='random seed (default: 543)')",
            "parser.add_argument('--render', action='store_true',",
            "\t\t\t\t\thelp='render the environment')",
            "parser.add_argument('--log-interval', type=int, default=10, metavar='N',",
            "\t\t\t\t\thelp='interval between training status logs (default: 10)')",
            "args = parser.parse_args()",
            "",
            "",
            "env = gym.make('CartPole-v0')",
            "env.seed(args.seed)",
            "torch.manual_seed(args.seed)",
            "",
            "",
            "SavedAction = namedtuple('SavedAction', ['log_prob', 'value'])",
            "",
            "",
            "class Policy(nn.Module):",
            "\t\"\"\"",
            "\timplements both actor and critic in one model",
            "\t\"\"\"",
            "\tdef __init__(self):",
            "\t\tsuper(Policy, self).__init__()",
            "\t\tself.affine1 = nn.Linear(4, 128)",
            "",
            "\t\t# actor's layer",
            "\t\tself.action_head = nn.Linear(128, 2)",
            "",
            "\t\t# critic's layer",
            "\t\tself.value_head = nn.Linear(128, 1)",
            "",
            "\t\t# action & reward buffer",
            "\t\tself.saved_actions = []",
            "\t\tself.rewards = []",
            "",
            "\tdef forward(self, x):",
            "\t\t\"\"\"",
            "\t\tforward of both actor and critic",
            "\t\t\"\"\"",
            "\t\tx = F.relu(self.affine1(x))",
            "",
            "\t\t# actor: choses action to take from state s_t",
            "\t\t# by returning probability of each action",
            "\t\taction_prob = F.softmax(self.action_head(x), dim=-1)",
            "",
            "\t\t# critic: evaluates being in the state s_t",
            "\t\tstate_values = self.value_head(x)",
            "",
            "\t\t# return values for both actor and critic as a tupel of 2 values:",
            "\t\t# 1. a list with the probability of each action over the action space",
            "\t\t# 2. the value from state s_t",
            "\t\treturn action_prob, state_values",
            "",
            "",
            "model = Policy()",
            "optimizer = optim.Adam(model.parameters(), lr=3e-2)",
            "eps = np.finfo(np.float32).eps.item()",
            "",
            "",
            "def select_action(state):",
            "\tstate = torch.from_numpy(state).float()",
            "\tprobs, state_value = model(state)",
            "",
            "\t# create a categorical distribution over the list of probabilities of actions",
            "\tm = Categorical(probs)",
            "",
            "\t# and sample an action using the distribution",
            "\taction = m.sample()",
            "",
            "\t# save to action buffer",
            "\tmodel.saved_actions.append(SavedAction(m.log_prob(action), state_value))",
            "",
            "\t# the action to take (left or right)",
            "\treturn action.item()",
            "",
            "",
            "def finish_episode():",
            "\t\"\"\"",
            "\tTraining code. Calcultes actor and critic loss and performs backprop.",
            "\t\"\"\"",
            "\tR = 0",
            "\tsaved_actions = model.saved_actions",
            "\tpolicy_losses = [] # list to save actor (policy) loss",
            "\tvalue_losses = [] # list to save critic (value) loss",
            "\treturns = [] # list to save the true values",
            "",
            "\t# calculate the true value using rewards returned from the environment",
            "\tfor r in model.rewards[::-1]:",
            "\t\t# calculate the discounted value",
            "\t\tR = r + args.gamma * R",
            "\t\treturns.insert(0, R)",
            "",
            "\treturns = torch.tensor(returns)",
            "\treturns = (returns - returns.mean()) / (returns.std() + eps)",
            "",
            "\tfor (log_prob, value), R in zip(saved_actions, returns):",
            "\t\tadvantage = R - value.item()",
            "",
            "\t\t# calculate actor (policy) loss",
            "\t\tpolicy_losses.append(-log_prob * advantage)",
            "",
            "\t\t# calculate critic (value) loss using L1 smooth loss",
            "\t\tvalue_losses.append(F.smooth_l1_loss(value, torch.tensor([R])))",
            "",
            "\t# reset gradients",
            "\toptimizer.zero_grad()",
            "",
            "\t# sum up all the values of policy_losses and value_losses",
            "\tloss = torch.stack(policy_losses).sum() + torch.stack(value_losses).sum()",
            "",
            "\t# perform backprop",
            "\tloss.backward()",
            "\toptimizer.step()",
            "",
            "\t# reset rewards and action buffer",
            "\tdel model.rewards[:]",
            "\tdel model.saved_actions[:]",
            "",
            "",
            "def main():",
            "\trunning_reward = 10",
            "",
            "\t# run inifinitely many episodes",
            "\tfor i_episode in count(1):",
            "",
            "\t\t# reset environment and episode reward",
            "\t\tstate = env.reset()",
            "\t\tep_reward = 0",
            "",
            "\t\t# for each episode, only run 9999 steps so that we don't",
            "\t\t# infinite loop while learning",
            "\t\tfor t in range(1, 10000):",
            "",
            "\t\t\t# select action from policy",
            "\t\t\taction = select_action(state)",
            "",
            "\t\t\t# take the action",
            "\t\t\tstate, reward, done, _ = env.step(action)",
            "",
            "\t\t\tif args.render:",
            "\t\t\t\tenv.render()",
            "",
            "\t\t\tmodel.rewards.append(reward)",
            "\t\t\tep_reward += reward",
            "\t\t\tif done:",
            "\t\t\t\tbreak",
            "",
            "\t\t# update cumulative reward",
            "\t\trunning_reward = 0.05 * ep_reward + (1 - 0.05) * running_reward",
            "",
            "\t\t# perform backprop",
            "\t\tfinish_episode()",
            "",
            "\t\t# log results",
            "\t\tif i_episode % args.log_interval == 0:",
            "\t\t\tprint('Episode {}\\tLast reward: {:.2f}\\tAverage reward: {:.2f}'.format(",
            "\t\t\t\t  i_episode, ep_reward, running_reward))",
            "",
            "\t\t# check if we have \"solved\" the cart pole problem",
            "\t\tif running_reward > env.spec.reward_threshold:",
            "\t\t\tprint(\"Solved! Running reward is now {} and \"",
            "\t\t\t\t  \"the last episode runs to {} time steps!\".format(running_reward, t))",
            "\t\t\tbreak",
            "",
            "",
            "if __name__ == '__main__':",
            "\tmain()"
        ]
    },
    "DCGAN Example": {
        "prefix": "pytorch:examples:dcgan",
        "description": "DCGAN code example",
        "body": [
            "from __future__ import print_function",
            "import argparse",
            "import os",
            "import random",
            "import torch",
            "import torch.nn as nn",
            "import torch.nn.parallel",
            "import torch.backends.cudnn as cudnn",
            "import torch.optim as optim",
            "import torch.utils.data",
            "import torchvision.datasets as dset",
            "import torchvision.transforms as transforms",
            "import torchvision.utils as vutils",
            "",
            "",
            "parser = argparse.ArgumentParser()",
            "parser.add_argument('--dataset', required=True, help='cifar10 | lsun | mnist |imagenet | folder | lfw | fake')",
            "parser.add_argument('--dataroot', required=True, help='path to dataset')",
            "parser.add_argument('--workers', type=int, help='number of data loading workers', default=2)",
            "parser.add_argument('--batchSize', type=int, default=64, help='input batch size')",
            "parser.add_argument('--imageSize', type=int, default=64, help='the height / width of the input image to network')",
            "parser.add_argument('--nz', type=int, default=100, help='size of the latent z vector')",
            "parser.add_argument('--ngf', type=int, default=64)",
            "parser.add_argument('--ndf', type=int, default=64)",
            "parser.add_argument('--niter', type=int, default=25, help='number of epochs to train for')",
            "parser.add_argument('--lr', type=float, default=0.0002, help='learning rate, default=0.0002')",
            "parser.add_argument('--beta1', type=float, default=0.5, help='beta1 for adam. default=0.5')",
            "parser.add_argument('--cuda', action='store_true', help='enables cuda')",
            "parser.add_argument('--ngpu', type=int, default=1, help='number of GPUs to use')",
            "parser.add_argument('--netG', default='', help=\"path to netG (to continue training)\")",
            "parser.add_argument('--netD', default='', help=\"path to netD (to continue training)\")",
            "parser.add_argument('--outf', default='.', help='folder to output images and model checkpoints')",
            "parser.add_argument('--manualSeed', type=int, help='manual seed')",
            "parser.add_argument('--classes', default='bedroom', help='comma separated list of classes for the lsun data set')",
            "",
            "opt = parser.parse_args()",
            "print(opt)",
            "",
            "try:",
            "\tos.makedirs(opt.outf)",
            "except OSError:",
            "\tpass",
            "",
            "if opt.manualSeed is None:",
            "\topt.manualSeed = random.randint(1, 10000)",
            "print(\"Random Seed: \", opt.manualSeed)",
            "random.seed(opt.manualSeed)",
            "torch.manual_seed(opt.manualSeed)",
            "",
            "cudnn.benchmark = True",
            "",
            "if torch.cuda.is_available() and not opt.cuda:",
            "\tprint(\"WARNING: You have a CUDA device, so you should probably run with --cuda\")",
            "",
            "if opt.dataset in ['imagenet', 'folder', 'lfw']:",
            "\t# folder dataset",
            "\tdataset = dset.ImageFolder(root=opt.dataroot,",
            "\t\t\t\t\t\t\t   transform=transforms.Compose([",
            "\t\t\t\t\t\t\t\t   transforms.Resize(opt.imageSize),",
            "\t\t\t\t\t\t\t\t   transforms.CenterCrop(opt.imageSize),",
            "\t\t\t\t\t\t\t\t   transforms.ToTensor(),",
            "\t\t\t\t\t\t\t\t   transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),",
            "\t\t\t\t\t\t\t   ]))",
            "\tnc=3",
            "elif opt.dataset == 'lsun':",
            "\tclasses = [ c + '_train' for c in opt.classes.split(',')]",
            "\tdataset = dset.LSUN(root=opt.dataroot, classes=classes,",
            "\t\t\t\t\t\ttransform=transforms.Compose([",
            "\t\t\t\t\t\t\ttransforms.Resize(opt.imageSize),",
            "\t\t\t\t\t\t\ttransforms.CenterCrop(opt.imageSize),",
            "\t\t\t\t\t\t\ttransforms.ToTensor(),",
            "\t\t\t\t\t\t\ttransforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),",
            "\t\t\t\t\t\t]))",
            "\tnc=3",
            "elif opt.dataset == 'cifar10':",
            "\tdataset = dset.CIFAR10(root=opt.dataroot, download=True,",
            "\t\t\t\t\t\t   transform=transforms.Compose([",
            "\t\t\t\t\t\t\t   transforms.Resize(opt.imageSize),",
            "\t\t\t\t\t\t\t   transforms.ToTensor(),",
            "\t\t\t\t\t\t\t   transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),",
            "\t\t\t\t\t\t   ]))",
            "\tnc=3",
            "",
            "elif opt.dataset == 'mnist':",
            "\t\tdataset = dset.MNIST(root=opt.dataroot, download=True,",
            "\t\t\t\t\t\t   transform=transforms.Compose([",
            "\t\t\t\t\t\t\t   transforms.Resize(opt.imageSize),",
            "\t\t\t\t\t\t\t   transforms.ToTensor(),",
            "\t\t\t\t\t\t\t   transforms.Normalize((0.5,), (0.5,)),",
            "\t\t\t\t\t\t   ]))",
            "\t\tnc=1",
            "",
            "elif opt.dataset == 'fake':",
            "\tdataset = dset.FakeData(image_size=(3, opt.imageSize, opt.imageSize),",
            "\t\t\t\t\t\t\ttransform=transforms.ToTensor())",
            "\tnc=3",
            "",
            "assert dataset",
            "dataloader = torch.utils.data.DataLoader(dataset, batch_size=opt.batchSize,",
            "\t\t\t\t\t\t\t\t         shuffle=True, num_workers=int(opt.workers))",
            "",
            "device = torch.device(\"cuda:0\" if opt.cuda else \"cpu\")",
            "ngpu = int(opt.ngpu)",
            "nz = int(opt.nz)",
            "ngf = int(opt.ngf)",
            "ndf = int(opt.ndf)",
            "",
            "",
            "# custom weights initialization called on netG and netD",
            "def weights_init(m):",
            "\tclassname = m.__class__.__name__",
            "\tif classname.find('Conv') != -1:",
            "\t\tm.weight.data.normal_(0.0, 0.02)",
            "\telif classname.find('BatchNorm') != -1:",
            "\t\tm.weight.data.normal_(1.0, 0.02)",
            "\t\tm.bias.data.fill_(0)",
            "",
            "",
            "class Generator(nn.Module):",
            "\tdef __init__(self, ngpu):",
            "\t\tsuper(Generator, self).__init__()",
            "\t\tself.ngpu = ngpu",
            "\t\tself.main = nn.Sequential(",
            "\t\t\t# input is Z, going into a convolution",
            "\t\t\tnn.ConvTranspose2d(     nz, ngf * 8, 4, 1, 0, bias=False),",
            "\t\t\tnn.BatchNorm2d(ngf * 8),",
            "\t\t\tnn.ReLU(True),",
            "\t\t\t# state size. (ngf*8) x 4 x 4",
            "\t\t\tnn.ConvTranspose2d(ngf * 8, ngf * 4, 4, 2, 1, bias=False),",
            "\t\t\tnn.BatchNorm2d(ngf * 4),",
            "\t\t\tnn.ReLU(True),",
            "\t\t\t# state size. (ngf*4) x 8 x 8",
            "\t\t\tnn.ConvTranspose2d(ngf * 4, ngf * 2, 4, 2, 1, bias=False),",
            "\t\t\tnn.BatchNorm2d(ngf * 2),",
            "\t\t\tnn.ReLU(True),",
            "\t\t\t# state size. (ngf*2) x 16 x 16",
            "\t\t\tnn.ConvTranspose2d(ngf * 2,     ngf, 4, 2, 1, bias=False),",
            "\t\t\tnn.BatchNorm2d(ngf),",
            "\t\t\tnn.ReLU(True),",
            "\t\t\t# state size. (ngf) x 32 x 32",
            "\t\t\tnn.ConvTranspose2d(    ngf,      nc, 4, 2, 1, bias=False),",
            "\t\t\tnn.Tanh()",
            "\t\t\t# state size. (nc) x 64 x 64",
            "\t\t)",
            "",
            "\tdef forward(self, input):",
            "\t\tif input.is_cuda and self.ngpu > 1:",
            "\t\t\toutput = nn.parallel.data_parallel(self.main, input, range(self.ngpu))",
            "\t\telse:",
            "\t\t\toutput = self.main(input)",
            "\t\treturn output",
            "",
            "",
            "netG = Generator(ngpu).to(device)",
            "netG.apply(weights_init)",
            "if opt.netG != '':",
            "\tnetG.load_state_dict(torch.load(opt.netG))",
            "print(netG)",
            "",
            "",
            "class Discriminator(nn.Module):",
            "\tdef __init__(self, ngpu):",
            "\t\tsuper(Discriminator, self).__init__()",
            "\t\tself.ngpu = ngpu",
            "\t\tself.main = nn.Sequential(",
            "\t\t\t# input is (nc) x 64 x 64",
            "\t\t\tnn.Conv2d(nc, ndf, 4, 2, 1, bias=False),",
            "\t\t\tnn.LeakyReLU(0.2, inplace=True),",
            "\t\t\t# state size. (ndf) x 32 x 32",
            "\t\t\tnn.Conv2d(ndf, ndf * 2, 4, 2, 1, bias=False),",
            "\t\t\tnn.BatchNorm2d(ndf * 2),",
            "\t\t\tnn.LeakyReLU(0.2, inplace=True),",
            "\t\t\t# state size. (ndf*2) x 16 x 16",
            "\t\t\tnn.Conv2d(ndf * 2, ndf * 4, 4, 2, 1, bias=False),",
            "\t\t\tnn.BatchNorm2d(ndf * 4),",
            "\t\t\tnn.LeakyReLU(0.2, inplace=True),",
            "\t\t\t# state size. (ndf*4) x 8 x 8",
            "\t\t\tnn.Conv2d(ndf * 4, ndf * 8, 4, 2, 1, bias=False),",
            "\t\t\tnn.BatchNorm2d(ndf * 8),",
            "\t\t\tnn.LeakyReLU(0.2, inplace=True),",
            "\t\t\t# state size. (ndf*8) x 4 x 4",
            "\t\t\tnn.Conv2d(ndf * 8, 1, 4, 1, 0, bias=False),",
            "\t\t\tnn.Sigmoid()",
            "\t\t)",
            "",
            "\tdef forward(self, input):",
            "\t\tif input.is_cuda and self.ngpu > 1:",
            "\t\t\toutput = nn.parallel.data_parallel(self.main, input, range(self.ngpu))",
            "\t\telse:",
            "\t\t\toutput = self.main(input)",
            "",
            "\t\treturn output.view(-1, 1).squeeze(1)",
            "",
            "",
            "netD = Discriminator(ngpu).to(device)",
            "netD.apply(weights_init)",
            "if opt.netD != '':",
            "\tnetD.load_state_dict(torch.load(opt.netD))",
            "print(netD)",
            "",
            "criterion = nn.BCELoss()",
            "",
            "fixed_noise = torch.randn(opt.batchSize, nz, 1, 1, device=device)",
            "real_label = 1",
            "fake_label = 0",
            "",
            "# setup optimizer",
            "optimizerD = optim.Adam(netD.parameters(), lr=opt.lr, betas=(opt.beta1, 0.999))",
            "optimizerG = optim.Adam(netG.parameters(), lr=opt.lr, betas=(opt.beta1, 0.999))",
            "",
            "for epoch in range(opt.niter):",
            "\tfor i, data in enumerate(dataloader, 0):",
            "\t\t############################",
            "\t\t# (1) Update D network: maximize log(D(x)) + log(1 - D(G(z)))",
            "\t\t###########################",
            "\t\t# train with real",
            "\t\tnetD.zero_grad()",
            "\t\treal_cpu = data[0].to(device)",
            "\t\tbatch_size = real_cpu.size(0)",
            "\t\tlabel = torch.full((batch_size,), real_label, device=device)",
            "",
            "\t\toutput = netD(real_cpu)",
            "\t\terrD_real = criterion(output, label)",
            "\t\terrD_real.backward()",
            "\t\tD_x = output.mean().item()",
            "",
            "\t\t# train with fake",
            "\t\tnoise = torch.randn(batch_size, nz, 1, 1, device=device)",
            "\t\tfake = netG(noise)",
            "\t\tlabel.fill_(fake_label)",
            "\t\toutput = netD(fake.detach())",
            "\t\terrD_fake = criterion(output, label)",
            "\t\terrD_fake.backward()",
            "\t\tD_G_z1 = output.mean().item()",
            "\t\terrD = errD_real + errD_fake",
            "\t\toptimizerD.step()",
            "",
            "\t\t############################",
            "\t\t# (2) Update G network: maximize log(D(G(z)))",
            "\t\t###########################",
            "\t\tnetG.zero_grad()",
            "\t\tlabel.fill_(real_label)  # fake labels are real for generator cost",
            "\t\toutput = netD(fake)",
            "\t\terrG = criterion(output, label)",
            "\t\terrG.backward()",
            "\t\tD_G_z2 = output.mean().item()",
            "\t\toptimizerG.step()",
            "",
            "\t\tprint('[%d/%d][%d/%d] Loss_D: %.4f Loss_G: %.4f D(x): %.4f D(G(z)): %.4f / %.4f'",
            "\t\t\t  % (epoch, opt.niter, i, len(dataloader),",
            "\t\t\t\t errD.item(), errG.item(), D_x, D_G_z1, D_G_z2))",
            "\t\tif i % 100 == 0:",
            "\t\t\tvutils.save_image(real_cpu,",
            "\t\t\t\t\t'%s/real_samples.png' % opt.outf,",
            "\t\t\t\t\tnormalize=True)",
            "\t\t\tfake = netG(fixed_noise)",
            "\t\t\tvutils.save_image(fake.detach(),",
            "\t\t\t\t\t'%s/fake_samples_epoch_%03d.png' % (opt.outf, epoch),",
            "\t\t\t\t\tnormalize=True)",
            "",
            "\t# do checkpointing",
            "\ttorch.save(netG.state_dict(), '%s/netG_epoch_%d.pth' % (opt.outf, epoch))",
            "\ttorch.save(netD.state_dict(), '%s/netD_epoch_%d.pth' % (opt.outf, epoch))"
        ]
    },
    "Variational Autoencoder Example": {
        "prefix": "pytorch:examples:vae",
        "description": "Variational autoencoder code example",
        "body": [
            "from __future__ import print_function",
            "import argparse",
            "import torch",
            "import torch.utils.data",
            "from torch import nn, optim",
            "from torch.nn import functional as F",
            "from torchvision import datasets, transforms",
            "from torchvision.utils import save_image",
            "",
            "",
            "parser = argparse.ArgumentParser(description='VAE MNIST Example')",
            "parser.add_argument('--batch-size', type=int, default=128, metavar='N',",
            "\t\t\t\t\thelp='input batch size for training (default: 128)')",
            "parser.add_argument('--epochs', type=int, default=10, metavar='N',",
            "\t\t\t\t\thelp='number of epochs to train (default: 10)')",
            "parser.add_argument('--no-cuda', action='store_true', default=False,",
            "\t\t\t\t\thelp='enables CUDA training')",
            "parser.add_argument('--seed', type=int, default=1, metavar='S',",
            "\t\t\t\t\thelp='random seed (default: 1)')",
            "parser.add_argument('--log-interval', type=int, default=10, metavar='N',",
            "\t\t\t\t\thelp='how many batches to wait before logging training status')",
            "args = parser.parse_args()",
            "args.cuda = not args.no_cuda and torch.cuda.is_available()",
            "",
            "torch.manual_seed(args.seed)",
            "",
            "device = torch.device(\"cuda\" if args.cuda else \"cpu\")",
            "",
            "kwargs = {'num_workers': 1, 'pin_memory': True} if args.cuda else {}",
            "train_loader = torch.utils.data.DataLoader(",
            "\tdatasets.MNIST('../data', train=True, download=True,",
            "\t\t\t\t   transform=transforms.ToTensor()),",
            "\tbatch_size=args.batch_size, shuffle=True, **kwargs)",
            "test_loader = torch.utils.data.DataLoader(",
            "\tdatasets.MNIST('../data', train=False, transform=transforms.ToTensor()),",
            "\tbatch_size=args.batch_size, shuffle=True, **kwargs)",
            "",
            "",
            "class VAE(nn.Module):",
            "\tdef __init__(self):",
            "\t\tsuper(VAE, self).__init__()",
            "",
            "\t\tself.fc1 = nn.Linear(784, 400)",
            "\t\tself.fc21 = nn.Linear(400, 20)",
            "\t\tself.fc22 = nn.Linear(400, 20)",
            "\t\tself.fc3 = nn.Linear(20, 400)",
            "\t\tself.fc4 = nn.Linear(400, 784)",
            "",
            "\tdef encode(self, x):",
            "\t\th1 = F.relu(self.fc1(x))",
            "\t\treturn self.fc21(h1), self.fc22(h1)",
            "",
            "\tdef reparameterize(self, mu, logvar):",
            "\t\tstd = torch.exp(0.5*logvar)",
            "\t\teps = torch.randn_like(std)",
            "\t\treturn mu + eps*std",
            "",
            "\tdef decode(self, z):",
            "\t\th3 = F.relu(self.fc3(z))",
            "\t\treturn torch.sigmoid(self.fc4(h3))",
            "",
            "\tdef forward(self, x):",
            "\t\tmu, logvar = self.encode(x.view(-1, 784))",
            "\t\tz = self.reparameterize(mu, logvar)",
            "\t\treturn self.decode(z), mu, logvar",
            "",
            "",
            "model = VAE().to(device)",
            "optimizer = optim.Adam(model.parameters(), lr=1e-3)",
            "",
            "",
            "# Reconstruction + KL divergence losses summed over all elements and batch",
            "def loss_function(recon_x, x, mu, logvar):",
            "\tBCE = F.binary_cross_entropy(recon_x, x.view(-1, 784), reduction='sum')",
            "",
            "\t# see Appendix B from VAE paper:",
            "\t# Kingma and Welling. Auto-Encoding Variational Bayes. ICLR, 2014",
            "\t# https://arxiv.org/abs/1312.6114",
            "\t# 0.5 * sum(1 + log(sigma^2) - mu^2 - sigma^2)",
            "\tKLD = -0.5 * torch.sum(1 + logvar - mu.pow(2) - logvar.exp())",
            "",
            "\treturn BCE + KLD",
            "",
            "",
            "def train(epoch):",
            "\tmodel.train()",
            "\ttrain_loss = 0",
            "\tfor batch_idx, (data, _) in enumerate(train_loader):",
            "\t\tdata = data.to(device)",
            "\t\toptimizer.zero_grad()",
            "\t\trecon_batch, mu, logvar = model(data)",
            "\t\tloss = loss_function(recon_batch, data, mu, logvar)",
            "\t\tloss.backward()",
            "\t\ttrain_loss += loss.item()",
            "\t\toptimizer.step()",
            "\t\tif batch_idx % args.log_interval == 0:",
            "\t\t\tprint('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(",
            "\t\t\t\tepoch, batch_idx * len(data), len(train_loader.dataset),",
            "\t\t\t\t100. * batch_idx / len(train_loader),",
            "\t\t\t\tloss.item() / len(data)))",
            "",
            "\tprint('====> Epoch: {} Average loss: {:.4f}'.format(",
            "\t\t  epoch, train_loss / len(train_loader.dataset)))",
            "",
            "",
            "def test(epoch):",
            "\tmodel.eval()",
            "\ttest_loss = 0",
            "\twith torch.no_grad():",
            "\t\tfor i, (data, _) in enumerate(test_loader):",
            "\t\t\tdata = data.to(device)",
            "\t\t\trecon_batch, mu, logvar = model(data)",
            "\t\t\ttest_loss += loss_function(recon_batch, data, mu, logvar).item()",
            "\t\t\tif i == 0:",
            "\t\t\t\tn = min(data.size(0), 8)",
            "\t\t\t\tcomparison = torch.cat([data[:n],",
            "\t\t\t\t\t\t\t\t      recon_batch.view(args.batch_size, 1, 28, 28)[:n]])",
            "\t\t\t\tsave_image(comparison.cpu(),",
            "\t\t\t\t\t\t 'results/reconstruction_' + str(epoch) + '.png', nrow=n)",
            "",
            "\ttest_loss /= len(test_loader.dataset)",
            "\tprint('====> Test set loss: {:.4f}'.format(test_loss))",
            "",
            "if __name__ == \"__main__\":",
            "\tfor epoch in range(1, args.epochs + 1):",
            "\t\ttrain(epoch)",
            "\t\ttest(epoch)",
            "\t\twith torch.no_grad():",
            "\t\t\tsample = torch.randn(64, 20).to(device)",
            "\t\t\tsample = model.decode(sample).cpu()",
            "\t\t\tsave_image(sample.view(64, 1, 28, 28),",
            "\t\t\t\t\t   'results/sample_' + str(epoch) + '.png')"
        ]
    }
}
